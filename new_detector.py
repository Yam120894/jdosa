import streamlit as st
import numpy as np
import librosa
import matplotlib.pyplot as plt
import cv2
import os
import tempfile
import tensorflow as tf
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
import glob
from sklearn.model_selection import train_test_split
from audiorecorder import audiorecorder
# Added for band-pass telephone filter
from scipy.signal import butter, lfilter

# Set page configuration
st.set_page_config(page_title="Simple Next Slide Detector", layout="wide")

# Set random seeds for reproducibility
np.random.seed(42)
tf.random.set_seed(42)

# Use legacy optimizer for M1/M2 Macs
if hasattr(tf.keras.optimizers, 'legacy'):
    tf.keras.optimizers.Adam = tf.keras.optimizers.legacy.Adam

# Initialize session state
if 'model' not in st.session_state:
    st.session_state.model = None
if 'next_slide_count' not in st.session_state:
    st.session_state.next_slide_count = 0
if 'prediction_history' not in st.session_state:
    st.session_state.prediction_history = []

# Set constants
FS = 16000  # Sample rate for audio processing
MODEL_PATH = "simple_next_slide_model.h5"

st.title("Simple Next Slide Detector")

# Function to train a new model


def train_new_model():
    st.write("### Loading and preparing data...")

    # Find all wav files in the dataset folders (generated by the user)
    positive_files = glob.glob("true/*.wav")
    negative_files = glob.glob("false/*.wav")

    if len(positive_files) == 0 or len(negative_files) == 0:
        st.error(
            "No training data found! Please place .wav files saying 'next slide' in the 'true' folder and other phrases in the 'false' folder.")
        return None

    st.write(
        f"Found {len(positive_files)} positive examples and {len(negative_files)} negative examples.")

    # Load and preprocess the data
    progress_bar = st.progress(0)
    data = []
    labels = []

    # Helper to convert an audio file to a 128x128 mel-spectrogram image
    def audio_to_spec(path):
        try:
            y, _ = librosa.load(path, sr=FS)
            # Normalise amplitude
            if np.max(np.abs(y)) > 0:
                y = y / np.max(np.abs(y))
            mel = librosa.feature.melspectrogram(
                y=y, sr=FS, n_mels=128, fmax=4096)
            mel_db = librosa.power_to_db(mel, ref=np.max)
            # Resize / pad along time axis to 128 frames
            if mel_db.shape[1] != 128:
                mel_db = cv2.resize(mel_db, (128, 128))
            # Scale to 0-255 grayscale for CNN (later normalised)
            mel_norm = (mel_db - mel_db.min()) / (mel_db.max() - mel_db.min())
            mel_img = (mel_norm * 255).astype(np.uint8)
            return mel_img
        except Exception as e:
            st.write(f"Error processing {path}: {e}")
            return None

    # Create a spectrogram from a raw audio array (used for augmentations)
    def array_to_spec(y):
        if len(y) == 0:
            return None
        # Normalise amplitude
        if np.max(np.abs(y)) > 0:
            y = y / np.max(np.abs(y))
        mel = librosa.feature.melspectrogram(y=y, sr=FS, n_mels=128, fmax=4096)
        mel_db = librosa.power_to_db(mel, ref=np.max)
        if mel_db.shape[1] != 128:
            mel_db = cv2.resize(mel_db, (128, 128))
        mel_norm = (mel_db - mel_db.min()) / (mel_db.max() - mel_db.min())
        mel_img = (mel_norm * 255).astype(np.uint8)
        return mel_img

    # Simple augmentation functions for positive samples
    def augment_audio(y):
        """Return a list of augmented versions of the input waveform."""
        augments = []
        try:
            # Pitch shift up 2 semitones
            augments.append(librosa.effects.pitch_shift(y, sr=FS, n_steps=2))
            # Pitch shift down 2 semitones
            augments.append(librosa.effects.pitch_shift(y, sr=FS, n_steps=-2))
            # Pitch shift up 4 semitones (simulate higher voice)
            augments.append(librosa.effects.pitch_shift(y, sr=FS, n_steps=4))
            # Pitch shift down 4 semitones (simulate deeper voice)
            augments.append(librosa.effects.pitch_shift(y, sr=FS, n_steps=-4))
            # Time stretch (slow 0.9x) – keep same length with resample
            stretched = librosa.effects.time_stretch(y, rate=0.9)
            if len(stretched) > 0:
                try:
                    augments.append(librosa.util.fix_length(
                        stretched, size=len(y)))
                except TypeError:
                    # Fallback for very old librosa versions expecting 'n' instead of 'size'
                    try:
                        augments.append(
                            librosa.util.fix_length(stretched, len(y)))
                    except Exception:
                        pass
            # Time stretch (fast 1.1x)
            stretched_fast = librosa.effects.time_stretch(y, rate=1.1)
            if len(stretched_fast) > 0:
                try:
                    augments.append(librosa.util.fix_length(
                        stretched_fast, size=len(y)))
                except TypeError:
                    try:
                        augments.append(librosa.util.fix_length(
                            stretched_fast, len(y)))
                    except Exception:
                        pass
            # Add white noise
            noise = np.random.randn(len(y)) * 0.005
            augments.append(y + noise)

            # Random time-shift (roll) by up to 0.2 s
            max_shift = int(0.2 * FS)
            shift = np.random.randint(-max_shift, max_shift)
            augments.append(np.roll(y, shift))

            # Random volume scaling (0.7–1.3)
            scale = np.random.uniform(0.7, 1.3)
            augments.append(y * scale)

            # Telephone-like band-pass (300–3400 Hz) filter
            def bandpass(sig, low, high, sr):
                nyq = 0.5 * sr
                low_norm = low / nyq
                high_norm = high / nyq
                b, a = butter(4, [low_norm, high_norm], btype='band')
                return lfilter(b, a, sig)

            augments.append(bandpass(y, 300, 3400, FS))
        except Exception as e:
            st.write(f"Augmentation error: {e}")
        return augments

    total_files = len(positive_files) + len(negative_files)

    # Process negative samples first (label 0) with augmentations as well
    for i, wav_path in enumerate(negative_files):
        try:
            y_neg, _ = librosa.load(wav_path, sr=FS)
        except Exception as e:
            st.write(f"Error loading {wav_path}: {e}")
            continue

        # original
        spec_neg = array_to_spec(y_neg)
        if spec_neg is not None:
            data.append(spec_neg)
            labels.append(0)

        # augmented variants (same function) – limit to first 7 to control size
        for y_aug in augment_audio(y_neg)[:7]:
            spec_aug = array_to_spec(y_aug)
            if spec_aug is not None:
                data.append(spec_aug)
                labels.append(0)

        progress_bar.progress((i + 1) / total_files)

    # Process positive samples (label 1) with augmentations
    for i, wav_path in enumerate(positive_files):
        try:
            y, _ = librosa.load(wav_path, sr=FS)
        except Exception as e:
            st.write(f"Error loading {wav_path}: {e}")
            continue

        # original
        spec = array_to_spec(y)
        if spec is not None:
            data.append(spec)
            labels.append(1)

        # augmented variants
        for y_aug in augment_audio(y):
            spec_aug = array_to_spec(y_aug)
            if spec_aug is not None:
                data.append(spec_aug)
                labels.append(1)

        progress_bar.progress((len(negative_files) + i + 1) / total_files)

    # Convert to numpy arrays
    X = np.array(data).reshape(-1, 128, 128, 1) / 255.0  # Normalize to 0-1
    y = np.array(labels)

    # Report final class counts after augmentations
    final_pos = int(np.sum(y == 1))
    final_neg = int(np.sum(y == 0))
    st.write(
        f"After augmentation: {final_pos} positive and {final_neg} negative spectrograms ready for training.")

    # Split into training and validation sets
    X_train, X_val, y_train, y_val = train_test_split(
        X, y, test_size=0.2, random_state=42)

    st.write(
        f"Training with {len(X_train)} samples, validating with {len(X_val)} samples")

    # Create a simple CNN model
    model = Sequential([
        # First convolutional block
        Conv2D(32, (3, 3), activation='relu',
               padding='same', input_shape=(128, 128, 1)),
        MaxPooling2D((2, 2)),
        Dropout(0.2),  # Add dropout after each convolutional block

        # Second convolutional block
        Conv2D(64, (3, 3), activation='relu', padding='same'),
        MaxPooling2D((2, 2)),
        Dropout(0.3),  # Increase dropout rate

        # Third convolutional block
        Conv2D(128, (3, 3), activation='relu', padding='same'),
        MaxPooling2D((2, 2)),
        Dropout(0.4),  # Increase dropout rate further

        # Flatten and dense layers
        Flatten(),
        Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(
            0.001)),  # Add L2 regularization
        Dropout(0.5),
        Dense(1, activation='sigmoid')
    ])

    # Compile model with class weights to balance the dataset
    model.compile(
        optimizer=tf.keras.optimizers.legacy.Adam(
            learning_rate=0.0005),  # Lower learning rate
        loss='binary_crossentropy',
        metrics=['accuracy']
    )

    st.write("### Training model...")

    # Train the model
    epochs = 20
    batch_size = 16

    # Create placeholders for progress display
    epoch_status = st.empty()
    charts = st.empty()

    # Track metrics for plotting
    history = {"loss": [], "accuracy": [], "val_loss": [], "val_accuracy": []}

    # Add early stopping to prevent overfitting
    early_stopping = tf.keras.callbacks.EarlyStopping(
        monitor='val_loss',
        patience=3,
        restore_best_weights=True
    )

    # Train through epochs with visual progress
    for epoch in range(epochs):
        epoch_status.write(f"Training epoch {epoch+1}/{epochs}")

        # Train for one epoch
        hist = model.fit(
            X_train, y_train,
            batch_size=batch_size,
            epochs=1,
            validation_data=(X_val, y_val),
            verbose=1,
            # Use dynamic class weights after augmentation
            class_weight={
                0: final_pos / (final_pos + final_neg),
                1: final_neg / (final_pos + final_neg)
            }
        )

        # Record metrics
        for key in history:
            history[key].append(hist.history[key][0])

        # Update charts
        fig, axes = plt.subplots(1, 2, figsize=(12, 4))

        # Plot loss
        axes[0].plot(range(1, epoch+2), history["loss"],
                     'b-', label="Training")
        axes[0].plot(range(1, epoch+2), history["val_loss"],
                     'r-', label="Validation")
        axes[0].set_title("Loss")
        axes[0].set_xlabel("Epoch")
        axes[0].set_ylabel("Loss")
        axes[0].legend()

        # Plot accuracy
        axes[1].plot(range(1, epoch+2), history["accuracy"],
                     'b-', label="Training")
        axes[1].plot(range(1, epoch+2), history["val_accuracy"],
                     'r-', label="Validation")
        axes[1].set_title("Accuracy")
        axes[1].set_xlabel("Epoch")
        axes[1].set_ylabel("Accuracy")
        axes[1].legend()

        charts.pyplot(fig)

    # Final evaluation
    eval_loss, eval_acc = model.evaluate(X_val, y_val, verbose=0)
    st.write(f"### Model evaluation")
    st.write(f"Validation accuracy: {eval_acc:.4f}")
    st.write(f"Validation loss: {eval_loss:.4f}")

    # Make test predictions on both real examples and synthetic data
    st.write("### Testing model on various inputs...")

    # Get a few test samples from the validation set
    positive_samples = X_val[y_val == 1][:5] if len(
        X_val[y_val == 1]) >= 5 else X_val[y_val == 1]
    negative_samples = X_val[y_val == 0][:5] if len(
        X_val[y_val == 0]) >= 5 else X_val[y_val == 0]

    # Test on positive examples
    st.write("#### Real 'Next Slide' examples:")
    positive_preds = []
    for i, sample in enumerate(positive_samples):
        pred = float(model.predict(sample.reshape(
            1, 128, 128, 1), verbose=0)[0][0])
        positive_preds.append(pred)
        st.write(f"Positive example {i+1}: {pred:.4f}")

    # Test on negative examples
    st.write("#### Real 'Not Next Slide' examples:")
    negative_preds = []
    for i, sample in enumerate(negative_samples):
        pred = float(model.predict(sample.reshape(
            1, 128, 128, 1), verbose=0)[0][0])
        negative_preds.append(pred)
        st.write(f"Negative example {i+1}: {pred:.4f}")

    # Additional synthetic tests
    random_input = np.random.random((1, 128, 128, 1))
    zeros_input = np.zeros((1, 128, 128, 1))
    ones_input = np.ones((1, 128, 128, 1))

    random_pred = float(model.predict(random_input, verbose=0)[0][0])
    zeros_pred = float(model.predict(zeros_input, verbose=0)[0][0])
    ones_pred = float(model.predict(ones_input, verbose=0)[0][0])

    st.write("#### Synthetic inputs:")
    st.write(f"Random noise prediction: {random_pred:.4f}")
    st.write(f"All zeros prediction: {zeros_pred:.4f}")
    st.write(f"All ones prediction: {ones_pred:.4f}")

    # Make sure the model isn't just returning the same value for everything
    if abs(random_pred - zeros_pred) < 0.01 and abs(random_pred - ones_pred) < 0.01:
        st.warning(
            "⚠️ Model seems to predict the same value for different inputs!")
    else:
        st.success("✅ Model shows variation in predictions for different inputs!")

    # Save the model
    model.save(MODEL_PATH)
    st.write(f"Model saved to {MODEL_PATH}")

    return model

# Function to process audio and make prediction


def process_audio(audio_data, model):
    # Convert to numpy array
    with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as f:
        audio_data.export(f.name, format="wav")
        audio_array, _ = librosa.load(f.name, sr=FS)
        os.unlink(f.name)

    # Create plot of audio waveform
    fig, ax = plt.subplots(figsize=(10, 2))
    times = np.arange(len(audio_array)) / FS
    ax.plot(times, audio_array)
    ax.set_title(f"Audio waveform - {len(audio_array)/FS:.2f}s")
    ax.set_xlabel("Time (s)")
    ax.set_ylabel("Amplitude")
    st.pyplot(fig)

    # Compute audio stats
    rms = np.sqrt(np.mean(audio_array**2))
    st.write(f"Audio RMS energy: {rms:.6f}")

    # Skip processing if audio is too quiet
    if rms < 0.001:
        st.warning("⚠️ Audio is too quiet - speak louder!")
        return None

    # Normalize
    audio_array = audio_array - np.mean(audio_array)
    max_abs = np.max(np.abs(audio_array))
    if max_abs > 0:
        audio_array = audio_array / max_abs

    # Create a mel spectrogram limited to 0–4096 Hz so the vertical axis spans
    # the desired frequency range.
    mel_spec = librosa.feature.melspectrogram(
        y=audio_array,
        sr=FS,
        n_mels=128,
        fmax=4096  # upper frequency bound for the y-axis
    )
    mel_db = librosa.power_to_db(mel_spec, ref=np.max)

    # Resize if needed
    if mel_db.shape[1] != 128:
        original_shape = mel_db.shape
        st.write(f"Resizing spectrogram from {original_shape} to (128, 128)")
        mel_db = cv2.resize(mel_db, (128, 128))

    # Plot spectrogram
    fig, ax = plt.subplots(figsize=(6, 6))
    # Map rows to 0–4096 Hz and ensure (0 Hz, 0 time-frame) is bottom-left
    img = ax.imshow(
        mel_db,
        origin="lower",
        aspect="auto",
        extent=[0, mel_db.shape[1], 0, 4096]  # x-axis (frames), y-axis (Hz)
    )
    ax.set_ylim(0, 4096)
    ax.set_xlabel("Time frame")
    ax.set_ylabel("Frequency (Hz)")
    ax.set_title("Mel Spectrogram (0–4096 Hz)")
    plt.colorbar(img, ax=ax)
    st.pyplot(fig)

    # Normalize for model input
    mel_norm = (mel_db - mel_db.min()) / (mel_db.max() - mel_db.min())
    model_input = mel_norm.reshape(1, 128, 128, 1)

    # Make prediction
    prediction = float(model.predict(model_input, verbose=0)[0][0])

    return prediction


# Check if trained model exists and load it
if os.path.exists(MODEL_PATH):
    st.write(f"Loading existing model from {MODEL_PATH}")
    try:
        st.session_state.model = load_model(MODEL_PATH)

        # Test the model with dummy input
        dummy = np.zeros((1, 128, 128, 1))
        dummy_pred = float(
            st.session_state.model.predict(dummy, verbose=0)[0][0])
        st.write(
            f"Model loaded successfully. Test prediction: {dummy_pred:.4f}")

    except Exception as e:
        st.error(f"Error loading model: {str(e)}")
        st.session_state.model = None

# Display current count
st.write(f"## Next Slide Count: {st.session_state.next_slide_count}")

# Training section
st.write("### Train Model")
st.write("Click the button below to train a new model from scratch using the spectrogram data.")

if st.button("🚀 Train New Model"):
    st.session_state.model = train_new_model()

# Recording section
st.write("### Test Detection")
st.write("Record your voice saying 'Next Slide' or other phrases to test the model.")

# Only show the recorder if we have a model
if st.session_state.model is not None:
    # Record audio
    audio = audiorecorder("Start Recording", "Stop Recording",
                          custom_style={'backgroundColor': '#4CAF50', 'color': 'white'})

    # Process if we have audio
    if len(audio) > 0:
        st.write("### Analyzing Recording")
        st.audio(audio.export().read())

        # Process and get prediction
        prediction = process_audio(audio, st.session_state.model)

        if prediction is not None:
            # Store prediction in history
            st.session_state.prediction_history.append(prediction)

            # Display result
            st.write(f"### Prediction: {prediction:.4f}")

            if prediction > 0.5:
                st.session_state.next_slide_count += 1
                st.success(
                    f"🎯 NEXT SLIDE detected! Count increased to {st.session_state.next_slide_count}")
            else:
                st.info("❌ Not a 'Next Slide' command")

            # Display prediction history
            if len(st.session_state.prediction_history) > 0:
                st.write("### Prediction History")
                fig, ax = plt.subplots(figsize=(10, 4))
                ax.plot(st.session_state.prediction_history)
                ax.axhline(y=0.5, color='r', linestyle='--')
                ax.set_ylim(0, 1)
                ax.set_xlabel("Recording #")
                ax.set_ylabel("Prediction")
                ax.set_title(
                    "Prediction History (values above 0.5 are 'Next Slide')")
                st.pyplot(fig)
else:
    st.warning("⚠️ Please train a model first before testing.")
